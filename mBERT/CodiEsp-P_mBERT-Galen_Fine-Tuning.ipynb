{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning mBERT-Galén on CodiEsp-P\n",
    "\n",
    "In this notebook, following a multi-label sequence classification approach, the mBERT-Galén model is fine-tuned on both the training and development sets of the CodiEsp-P corpus. Additionally, the predictions made by the model on the test set are saved, in order to futher evaluate the clinical coding performance of the model (see `results/CodiEsp-P/Evaluation.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Auxiliary components\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from nlp_utils import *\n",
    "\n",
    "# mBERT tokenizer\n",
    "from keras_bert import load_vocabulary, Tokenizer\n",
    "model_path = \"multi_cased_L-12_H-768_A-12/\"\n",
    "config_path = model_path + \"bert_config.json\"\n",
    "checkpoint_path = \"mBERT-Galen/model.ckpt-1000000\"\n",
    "vocab_file = \"vocab.txt\"\n",
    "tokenizer = Tokenizer(token_dict=load_vocabulary(model_path + vocab_file), pad_index=0, cased=True)\n",
    "\n",
    "# Hyper-parameters\n",
    "text_col = \"raw_text\"\n",
    "training = False\n",
    "trainable = True\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 34\n",
    "LR = 3e-5\n",
    "\n",
    "random_seed = 0\n",
    "tf.set_random_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load text\n",
    "\n",
    "Firstly, all text files from training and development CodiEsp corpora are loaded in different dataframes.\n",
    "\n",
    "Also, CIE-Procedimiento codes are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../datasets/codiesp_v4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.81 ms, sys: 0 ns, total: 9.81 ms\n",
      "Wall time: 9.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_path = corpus_path + \"train/text_files/\"\n",
    "train_files = [f for f in os.listdir(train_path) if os.path.isfile(train_path + f)]\n",
    "train_data = load_text_files(train_files, train_path)\n",
    "df_text_train = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in train_files], 'raw_text': train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142007000600016-2</td>\n",
       "      <td>Paciente varón de 35 años con tumoración en po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1137-66272009000500017-1</td>\n",
       "      <td>Lactante de sexo femenino que ingresó a los 7 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0365-66912007001100010-1</td>\n",
       "      <td>Paciente de 63 años que refería déficit de agu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0365-66912009000300010-1</td>\n",
       "      <td>Se presenta el caso de un varón de 24 años de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0211-69952013000500035-1</td>\n",
       "      <td>Se presenta el caso de un varón de 64 años sin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S0004-06142007000600016-2   \n",
       "1  S1137-66272009000500017-1   \n",
       "2  S0365-66912007001100010-1   \n",
       "3  S0365-66912009000300010-1   \n",
       "4  S0211-69952013000500035-1   \n",
       "\n",
       "                                            raw_text  \n",
       "0  Paciente varón de 35 años con tumoración en po...  \n",
       "1  Lactante de sexo femenino que ingresó a los 7 ...  \n",
       "2  Paciente de 63 años que refería déficit de agu...  \n",
       "3  Se presenta el caso de un varón de 24 años de ...  \n",
       "4  Se presenta el caso de un varón de 64 años sin...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paciente varón de 35 años con tumoración en polo superior de teste derecho hallada de manera casual durante una autoexploración, motivo por el cual acude a consulta de urología donde se realiza exploración física, apreciando masa de 1cm aproximado de diámetro dependiente de epidídimo, y ecografía testicular, que se informa como lesión nodular sólida en cabeza de epidídimo derecho. Se realiza RMN. Confirmando masa nodular, siendo el tumor adenomatoide de epidídimo la primera posibilidad diagnóstica.\\n\\nSe decide, en los dos casos, resección quirúrgica de tumoración nodular en cola epidídimo derecho, sin realización de orquiectomía posterior.\\nEn ambos casos se realizó examen anátomopatológico de la pieza quirúrgica. Hallazgos histológicos macroscópicos: formación nodular de 1,5 cms (caso1) y 1,2 cms (caso 2) de consistencia firme, coloración blanquecina y bien delimitada. Microscópicamente se observa proliferación tumoral constituida por estructuras tubulares en las que la celularidad muestra núcleos redondeados y elongados sin atipia citológica y que ocasionalmente muestra citoplasmas vacuolados, todo ello compatible con tumor adenomatoide de epidídimo.\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_train.raw_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the CIE-Procedimiento codes table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train = pd.read_table(corpus_path + \"train/trainP.tsv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train.columns = [\"doc_id\", \"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1550, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bw03zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>3e02329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bw40zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bv44zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bn20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id     code\n",
       "0  S0004-06142005000700014-1  bw03zzz\n",
       "1  S0004-06142005000700014-1  3e02329\n",
       "2  S0004-06142005000700014-1  bw40zzz\n",
       "3  S0004-06142005000700014-1  bv44zzz\n",
       "4  S0004-06142005000700014-1     bn20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_codes_train[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.87 ms, sys: 165 µs, total: 6.03 ms\n",
      "Wall time: 5.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dev_path = corpus_path + \"dev/text_files/\"\n",
    "dev_files = [f for f in os.listdir(dev_path) if os.path.isfile(dev_path + f)]\n",
    "dev_data = load_text_files(dev_files, dev_path)\n",
    "df_text_dev = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in dev_files], 'raw_text': dev_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1698-44472004000100009-1</td>\n",
       "      <td>Varón de 64 años de edad con tumefacción mandi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1139-76322015000300013-1</td>\n",
       "      <td>Niña de tres años que acude a Urgencias tras l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-05582015000100004-1</td>\n",
       "      <td>Se presenta el caso de una mujer de 60 años de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1887-85712015000200005-1</td>\n",
       "      <td>Paciente varón de cinco años de edad que tras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1699-65852010000300002-1</td>\n",
       "      <td>LTR. Paciente de sexo masculino, de 32 años de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1698-44472004000100009-1   \n",
       "1  S1139-76322015000300013-1   \n",
       "2  S1130-05582015000100004-1   \n",
       "3  S1887-85712015000200005-1   \n",
       "4  S1699-65852010000300002-1   \n",
       "\n",
       "                                            raw_text  \n",
       "0  Varón de 64 años de edad con tumefacción mandi...  \n",
       "1  Niña de tres años que acude a Urgencias tras l...  \n",
       "2  Se presenta el caso de una mujer de 60 años de...  \n",
       "3  Paciente varón de cinco años de edad que tras ...  \n",
       "4  LTR. Paciente de sexo masculino, de 32 años de...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Varón de 64 años de edad con tumefacción mandibular derecha de 6 meses de evolución. La radiografía simple mostraba una lesión expansiva bien delimitada, osteolítica, multiloculada, localizada en rama horizontal mandibular. La tomografía computerizada presentaba una lesión expansiva con destrucción de la cortical ósea. Con el diagnóstico provisional de probable ameloblastoma se procedió a la resección-biopsia de la lesión. Mediante incisión interpapilar se expuso la mandíbula que mostraba la superficie abombada y destruída por una tumoración carnosa de consistencia densa que rodeaba la rama del nervio dentario inferior. Tras un cuidadoso curetaje de la cavidad ósea se reconstruyó la mandíbula y se repuso la mucosa. No hubo complicaciones postquirúrgicas.\\n\\nEl material remitido a Anatomía Patológica consistía en fragmentos tumorales de unos 2x1.5 cm, blanco-grisáceos al corte y de consistencia firme. Se tomaron diversas muestras que tras fijarse en formaldehído se incluyeron en parafina y se procesaron mediante técnicas de rutina: se cortaron secciones de 4m de grosor que se tiñeron con hematoxilina-eosina. Se procedió a estudio inmunohistoquímico de cortes representativos mediante el método avidina-biotina peroxidasa, utilizando anticuerpos primarios anti antígeno de membrana epitelial EMA, (Dako M613, USA, 10/500), proteína S-100 (Dako, L1845, USA, prediluída), neurofilamentos (Biogenex 6670-0154, USA), enolasa neuroespecífica NSE, (Biogenex MU055-VC, USA, 10/1000), CD57 (Becton-Dickinson 7660, USA, 10/500), CD34 (Becton-Dickinson 7660, USA, 10/500), a-actina de músculo liso (Dako MO851, USA, 10/200), desmina (Dako M760, USA, 10/500), y vimentina (Shandon 402255, USA, pred.). El proceso se realizó siguiendo el protocolo estándar, utilizando controles positivos y negativos.\\nLa hibridización in situ con fluorescencia (FISH) se realizó en cortes parafinados de 50m de espesor mediante un mezclador de doble color LSI BCR/ABL (VYSIS Inc, Downers Grove, USA) siguiendo el procedimiento recomendado por el fabricante y se examinaron con un microscopio de fluorescencia Nikon con un filtro de triple banda, siendo estudiados un centenar de núcleos por dos de los autores.\\nHistológicamente los fragmentos tumorales estaban constituídos por células alargadas de forma y tamaño regulares dispuestas en haces entrelazados y en remolinos estructurados en \"bulbo de cebolla\". La densidad celular y del estroma intercelular eran variables, con algunas zonas mostrando aspecto mixoide. No se apreciaron células dispuestas en empalizada ni se observaron pleomorfimso celular o mitosis atípicas. En la periferia de algunos fragmentos se identificaron fibras residuales del tronco nervioso mandibular. Con el diagnóstico provisional de PIN se procedió a los examenes complementarios.\\n\\nLa inmunohistoquímica mostró que las células tumorales eran intensamente positivas para el EMA y la vimentina y negativas para la proteína S-100, NSE, colágeno IV, CD57, a-actina de músculo liso, desmina y CD34. Las células de Schwann en los remolinos eran positivas para la proteína S-100 y en el centro de los \"bulbos\" se identificaron axones positivos para el antígeno anti-neurofilamento. Las fibras residuales del nervio dentario eran positivas para la proteína S-100, la NSE y los neurofilamentos y el perineurio positivo para el EMA.\\n\\nLa hibridización in situ con fluorescencia reveló una delección del brazo largo del cromosoma 22 (22q11) en los núcleos del 75% de las células tumorales así como pérdida de centrómero del cromosoma 22.\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_dev.raw_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the CIE-Procedimiento codes table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev = pd.read_table(corpus_path + \"dev/devP.tsv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev.columns = [\"doc_id\", \"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>bt41zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>ct13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005001000011-1</td>\n",
       "      <td>3e1m39z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005001000011-1</td>\n",
       "      <td>0tcb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005001000011-1</td>\n",
       "      <td>bt02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id     code\n",
       "0  S0004-06142005000900016-1  bt41zzz\n",
       "1  S0004-06142005000900016-1     ct13\n",
       "2  S0004-06142005001000011-1  3e1m39z\n",
       "3  S0004-06142005001000011-1     0tcb\n",
       "4  S0004-06142005001000011-1     bt02"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_codes_dev[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join the training and development CodiEsp codes dataframes together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_dev = pd.concat([df_codes_train, df_codes_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2367, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_train_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bw03zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>3e02329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bw40zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bv44zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>bn20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id     code\n",
       "0  S0004-06142005000700014-1  bw03zzz\n",
       "1  S0004-06142005000700014-1  3e02329\n",
       "2  S0004-06142005000700014-1  bw40zzz\n",
       "3  S0004-06142005000700014-1  bv44zzz\n",
       "4  S0004-06142005000700014-1     bn20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_train_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating corpora of annotated sentences\n",
    "\n",
    "Leveraging the information available for the named-entity-recognition and normalization (NER-N) CodiEsp-X task, we create both a training and a development corpus of annotated sentences with CIE-Procedimiento codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we pre-process the NER-N precedure-codes annotations available for both the training and development corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.26 ms, sys: 3.97 ms, total: 11.2 ms\n",
      "Wall time: 10.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "codiesp_x_train = pd.read_table(corpus_path + \"train/trainX.tsv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "codiesp_x_train.columns = [\"doc_id\", \"type\", \"code\", \"word\", \"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9181, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codiesp_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>type</th>\n",
       "      <th>code</th>\n",
       "      <th>word</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bw03zzz</td>\n",
       "      <td>Rx tórax</td>\n",
       "      <td>2163 2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>3e02329</td>\n",
       "      <td>Estreptomicina intramuscular</td>\n",
       "      <td>2787 2801;2810 2823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>DIAGNOSTICO</td>\n",
       "      <td>n44.8</td>\n",
       "      <td>teste derecho aumentado de tamaño</td>\n",
       "      <td>1343 1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>DIAGNOSTICO</td>\n",
       "      <td>z20.818</td>\n",
       "      <td>exposición a Brucella</td>\n",
       "      <td>594 615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>DIAGNOSTICO</td>\n",
       "      <td>r60.9</td>\n",
       "      <td>edemas</td>\n",
       "      <td>1250 1256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id           type     code  \\\n",
       "0  S0004-06142005000700014-1  PROCEDIMIENTO  bw03zzz   \n",
       "1  S0004-06142005000700014-1  PROCEDIMIENTO  3e02329   \n",
       "2  S0004-06142005000700014-1    DIAGNOSTICO    n44.8   \n",
       "3  S0004-06142005000700014-1    DIAGNOSTICO  z20.818   \n",
       "4  S0004-06142005000700014-1    DIAGNOSTICO    r60.9   \n",
       "\n",
       "                                word             location  \n",
       "0                           Rx tórax            2163 2171  \n",
       "1       Estreptomicina intramuscular  2787 2801;2810 2823  \n",
       "2  teste derecho aumentado de tamaño            1343 1376  \n",
       "3              exposición a Brucella              594 615  \n",
       "4                             edemas            1250 1256  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codiesp_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "codiesp_x_train = codiesp_x_train[codiesp_x_train[\"type\"] == \"PROCEDIMIENTO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1972, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codiesp_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner = process_ner_labels(codiesp_x_train).sort_values([\"doc_id\", \"start\", \"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>type</th>\n",
       "      <th>code</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bw03zzz</td>\n",
       "      <td>Rx tórax</td>\n",
       "      <td>2163</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bw40zzz</td>\n",
       "      <td>Ecografía abdominal</td>\n",
       "      <td>2173</td>\n",
       "      <td>2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bn20</td>\n",
       "      <td>TAC craneal</td>\n",
       "      <td>2194</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bv44zzz</td>\n",
       "      <td>Ecografía testicular</td>\n",
       "      <td>2287</td>\n",
       "      <td>2307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000700014-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>3e02329</td>\n",
       "      <td>Estreptomicina intramuscular</td>\n",
       "      <td>2787</td>\n",
       "      <td>2801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id           type     code  \\\n",
       "0  S0004-06142005000700014-1  PROCEDIMIENTO  bw03zzz   \n",
       "3  S0004-06142005000700014-1  PROCEDIMIENTO  bw40zzz   \n",
       "5  S0004-06142005000700014-1  PROCEDIMIENTO     bn20   \n",
       "4  S0004-06142005000700014-1  PROCEDIMIENTO  bv44zzz   \n",
       "1  S0004-06142005000700014-1  PROCEDIMIENTO  3e02329   \n",
       "\n",
       "                           word start   end  \n",
       "0                      Rx tórax  2163  2171  \n",
       "3           Ecografía abdominal  2173  2192  \n",
       "5                   TAC craneal  2194  2205  \n",
       "4          Ecografía testicular  2287  2307  \n",
       "1  Estreptomicina intramuscular  2787  2801  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_train_ner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2769, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_train_ner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.82 ms, sys: 0 ns, total: 7.82 ms\n",
      "Wall time: 6.87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "codiesp_x_dev = pd.read_table(corpus_path + \"dev/devX.tsv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "codiesp_x_dev.columns = [\"doc_id\", \"type\", \"code\", \"word\", \"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4477, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codiesp_x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>type</th>\n",
       "      <th>code</th>\n",
       "      <th>word</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bt41zzz</td>\n",
       "      <td>ecografía renal derecha</td>\n",
       "      <td>307 316;348 361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>ct13</td>\n",
       "      <td>gammagrafía renal</td>\n",
       "      <td>739 756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>DIAGNOSTICO</td>\n",
       "      <td>q62.11</td>\n",
       "      <td>estenosis en la unión pieloureteral derecha</td>\n",
       "      <td>540 583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>DIAGNOSTICO</td>\n",
       "      <td>n28.89</td>\n",
       "      <td>ectasia pielocalicial</td>\n",
       "      <td>326 347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>DIAGNOSTICO</td>\n",
       "      <td>n39.0</td>\n",
       "      <td>infecciones del tracto urinario</td>\n",
       "      <td>198 229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id           type     code  \\\n",
       "0  S0004-06142005000900016-1  PROCEDIMIENTO  bt41zzz   \n",
       "1  S0004-06142005000900016-1  PROCEDIMIENTO     ct13   \n",
       "2  S0004-06142005000900016-1    DIAGNOSTICO   q62.11   \n",
       "3  S0004-06142005000900016-1    DIAGNOSTICO   n28.89   \n",
       "4  S0004-06142005000900016-1    DIAGNOSTICO    n39.0   \n",
       "\n",
       "                                          word         location  \n",
       "0                      ecografía renal derecha  307 316;348 361  \n",
       "1                            gammagrafía renal          739 756  \n",
       "2  estenosis en la unión pieloureteral derecha          540 583  \n",
       "3                        ectasia pielocalicial          326 347  \n",
       "4              infecciones del tracto urinario          198 229  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codiesp_x_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "codiesp_x_dev = codiesp_x_dev[codiesp_x_dev[\"type\"] == \"PROCEDIMIENTO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1046, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codiesp_x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner = process_ner_labels(codiesp_x_dev).sort_values([\"doc_id\", \"start\", \"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>type</th>\n",
       "      <th>code</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bt41zzz</td>\n",
       "      <td>ecografía renal derecha</td>\n",
       "      <td>307</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>bt41zzz</td>\n",
       "      <td>ecografía renal derecha</td>\n",
       "      <td>348</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>ct13</td>\n",
       "      <td>gammagrafía renal</td>\n",
       "      <td>739</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005001000011-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>3e1m39z</td>\n",
       "      <td>diálisis peritoneal</td>\n",
       "      <td>95</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S0004-06142005001000011-1</td>\n",
       "      <td>PROCEDIMIENTO</td>\n",
       "      <td>0270</td>\n",
       "      <td>angioplastia transluminal de la coronaria derecha</td>\n",
       "      <td>424</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id           type     code  \\\n",
       "0  S0004-06142005000900016-1  PROCEDIMIENTO  bt41zzz   \n",
       "1  S0004-06142005000900016-1  PROCEDIMIENTO  bt41zzz   \n",
       "2  S0004-06142005000900016-1  PROCEDIMIENTO     ct13   \n",
       "3  S0004-06142005001000011-1  PROCEDIMIENTO  3e1m39z   \n",
       "7  S0004-06142005001000011-1  PROCEDIMIENTO     0270   \n",
       "\n",
       "                                                word start  end  \n",
       "0                            ecografía renal derecha   307  316  \n",
       "1                            ecografía renal derecha   348  361  \n",
       "2                                  gammagrafía renal   739  756  \n",
       "3                                diálisis peritoneal    95  114  \n",
       "7  angioplastia transluminal de la coronaria derecha   424  473  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_dev_ner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1540, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_dev_ner.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the character start-end positions of each sentence from the CodiEsp corpus (see `datasets/CodiEsp-Sentence-Split.ipynb`), we annotate the sentences with CIE-Procedimiento codes. Also, using mBERT tokenizer, each sentence is converted into a sequence of subwords, which are further converted into vocabulary indices (input IDs) and segments arrays (BERT input tensors). We also generate a *fragments* dataset indicating the number of produced annotated sentences for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-Split information\n",
    "ss_corpus_path = \"../datasets/CodiEsp-SSplit-text/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = list(df_codes_train_dev[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2367"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb_encoder = MultiLabelBinarizer()\n",
    "mlb_encoder.fit([label_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of distinct codes\n",
    "num_labels = len(mlb_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only training texts that are annotated with CIE-Procedimiento codes are considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some train documents (texts) are not annotated \n",
    "len(set(df_text_train[\"doc_id\"]) - set(df_codes_train_ner[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_list = sorted(set(df_codes_train_ner[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.65 ms, sys: 7.8 ms, total: 16.4 ms\n",
      "Wall time: 15.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ss_sub_corpus_path = ss_corpus_path + \"train/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_train = load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:06<00:00, 66.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.63 s, sys: 38.5 ms, total: 6.67 s\n",
      "Wall time: 6.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ind, train_seg, train_y, train_frag, train_start_end_frag = ss_create_frag_input_data_bert(df_text=df_text_train, \n",
    "                                                  text_col=text_col, \n",
    "                                                  df_ann=df_codes_train_ner, doc_list=train_doc_list, ss_dict=ss_dict_train,\n",
    "                                                  tokenizer=tokenizer, lab_encoder=mlb_encoder, seq_len=SEQ_LEN,\n",
    "                                                  greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7025, 128)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7025, 128)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7025, 727)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7025"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_start_end_frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    435.000000\n",
       "mean      16.149425\n",
       "std        7.778513\n",
       "min        4.000000\n",
       "25%       10.500000\n",
       "50%       15.000000\n",
       "75%       20.000000\n",
       "max       54.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check n_frag distribution across texts\n",
    "pd.Series(train_frag).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a randomly selected text and its encoded version\n",
    "check_id = np.random.randint(low=0, high=len(train_doc_list), size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S1137-66272008000500007-1'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc_list[check_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gestante de 27 años, del grupo sanguíneo A positivo, con antecedentes personales de meningitis a los 3 años, legrado por embarazo molar (G1P0A1) en su primera gestación en 2005 y fumadora de 10-20 cigarrillos/día. No antecedentes transfusionales previos.\\nEn la ecografía realizada en la semana 35 de gestación se detectó una hidrocefalia fetal bilateral y oligoamnios, por lo que se programó una cesárea para la semana 36. En el estudio analítico previo destacaba una serología positiva (IgM) para el Parvovirus B19. La exploración de la recién nacida tras la cesárea, reveló un buen estado general, con un test de Apgar de 8 y 9 puntos en el 1º y 5º minuto, respectivamente, pequeños hematomas en hombro y glúteo izquierdos, macrocefalia con fontanela anterior a tensión y prominencia de las venas cefálicas. En el hemograma se constató una tombocitopenia grave (9 x 109/L). Ante la sospecha clínica de TFNA se transfundió una alícuota de concentrado de plaquetas de aféresis irradiado, de fenotipo HPA-1a desconocido y se inició tratamiento con inmunoglobulinas endovenosas (IGIV) a dosis de 1 g/Kg x 2 días, con muy buena respuesta (plaquetas > 100 x 109/L, que se mantuvieron a lo largo de todo el ingreso). Se solicitó estudio inmunohematológico al Centro de Transfusión Sanguínea de Navarra, así como búsqueda de plaquetas de donante HPA-1a negativo.\\nEn la ecografía cerebral se apreció una hidrocefalia grave secundaria a hemorragia intraventricular, que precisó de la colocación de un catéter de derivación externo, a través del cual se recogió líquido cefalorraquídeo hemorrágico a presión. Presentó una evolución posterior tórpida, con ventriculitis y crisis convulsivas, que precisó de tratamiento con antibioterapia y fenobarbital, respectivamente, e implantación de una válvula de derivación ventrículoperitoneal. Durante su ingreso se transfundió una alícuota de concentrado de hematíes leucodepleccionado e irradiado.\\nEl estudio inmunohematológico realizado en el Centro de Transfusión Sanguínea de Navarra confirmó el fenotipo HPA-1a negativo materno y positivo en el neonato, así como la presencia de anticuerpos con especificidad anti-HPA-1a en el suero materno como en la recién nacida.\\n\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_train[df_text_train[\"doc_id\"] == train_doc_list[check_id]][text_col].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[()] \n",
      "\n",
      "[()] \n",
      "\n",
      "[('10d00z1',)] \n",
      "\n",
      "[()] \n",
      "\n",
      "[('10d00z1',)] \n",
      "\n",
      "[()] \n",
      "\n",
      "[()] \n",
      "\n",
      "[()] \n",
      "\n",
      "[('b040zzz',)] \n",
      "\n",
      "[('0016',)] \n",
      "\n",
      "[()] \n",
      "\n",
      "[()] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_id_frag = sum(train_frag[:check_id])\n",
    "for i in range(check_id_frag, check_id_frag + train_frag[check_id]):\n",
    "    print(mlb_encoder.inverse_transform(np.array([train_y[i]])), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('G', (0, 1)), ('##estan', (1, 6)), ('##te', (6, 8)), ('de', (9, 11)), ('27', (12, 14)), ('años', (15, 19)), (',', (19, 20)), ('del', (21, 24)), ('grupo', (25, 30)), ('sang', (31, 35)), ('##u', (35, 36)), ('##íne', (36, 39)), ('##o', (39, 40)), ('A', (41, 42)), ('positivo', (43, 51)), (',', (51, 52)), ('con', (53, 56)), ('ante', (57, 61)), ('##cedent', (61, 67)), ('##es', (67, 69)), ('personales', (70, 80)), ('de', (81, 83)), ('mening', (84, 90)), ('##itis', (90, 94)), ('a', (95, 96)), ('los', (97, 100)), ('3', (101, 102)), ('años', (103, 107)), (',', (107, 108)), ('leg', (109, 112)), ('##rado', (112, 116)), ('por', (117, 120)), ('em', (121, 123)), ('##bara', (123, 127)), ('##zo', (127, 129)), ('mol', (130, 133)), ('##ar', (133, 135)), ('(', (136, 137)), ('G1', (137, 139)), ('##P', (139, 140)), ('##0', (140, 141)), ('##A', (141, 142)), ('##1', (142, 143)), (')', (143, 144)), ('en', (145, 147)), ('su', (148, 150)), ('primera', (151, 158)), ('ge', (159, 161)), ('##sta', (161, 164)), ('##ción', (164, 168)), ('en', (169, 171)), ('2005', (172, 176)), ('y', (177, 178)), ('fu', (179, 181)), ('##mad', (181, 184)), ('##ora', (184, 187)), ('de', (188, 190)), ('10', (191, 193)), ('-', (193, 194)), ('20', (194, 196)), ('ci', (197, 199)), ('##garri', (199, 204)), ('##llos', (204, 208)), ('/', (208, 209)), ('día', (209, 212)), ('.', (212, 213))]\n",
      "\n",
      "\n",
      "[('No', (214, 216)), ('ante', (217, 221)), ('##cedent', (221, 227)), ('##es', (227, 229)), ('trans', (230, 235)), ('##fus', (235, 238)), ('##ional', (238, 243)), ('##es', (243, 245)), ('pre', (246, 249)), ('##vios', (249, 253)), ('.', (253, 254))]\n",
      "\n",
      "\n",
      "[('En', (255, 257)), ('la', (258, 260)), ('e', (261, 262)), ('##co', (262, 264)), ('##grafía', (264, 270)), ('realizada', (271, 280)), ('en', (281, 283)), ('la', (284, 286)), ('semana', (287, 293)), ('35', (294, 296)), ('de', (297, 299)), ('ge', (300, 302)), ('##sta', (302, 305)), ('##ción', (305, 309)), ('se', (310, 312)), ('det', (313, 316)), ('##ect', (316, 319)), ('##ó', (319, 320)), ('una', (321, 324)), ('hi', (325, 327)), ('##dro', (327, 330)), ('##ce', (330, 332)), ('##fal', (332, 335)), ('##ia', (335, 337)), ('fet', (338, 341)), ('##al', (341, 343)), ('bila', (344, 348)), ('##teral', (348, 353)), ('y', (354, 355)), ('oli', (356, 359)), ('##goa', (359, 362)), ('##mn', (362, 364)), ('##ios', (364, 367)), (',', (367, 368)), ('por', (369, 372)), ('lo', (373, 375)), ('que', (376, 379)), ('se', (380, 382)), ('program', (383, 390)), ('##ó', (390, 391)), ('una', (392, 395)), ('ces', (396, 399)), ('##ár', (399, 401)), ('##ea', (401, 403)), ('para', (404, 408)), ('la', (409, 411)), ('semana', (412, 418)), ('36', (419, 421)), ('.', (421, 422))]\n",
      "\n",
      "\n",
      "[('En', (423, 425)), ('el', (426, 428)), ('estudio', (429, 436)), ('anal', (437, 441)), ('##ítico', (441, 446)), ('pre', (447, 450)), ('##vio', (450, 453)), ('destaca', (454, 461)), ('##ba', (461, 463)), ('una', (464, 467)), ('ser', (468, 471)), ('##ología', (471, 477)), ('positiva', (478, 486)), ('(', (487, 488)), ('I', (488, 489)), ('##g', (489, 490)), ('##M', (490, 491)), (')', (491, 492)), ('para', (493, 497)), ('el', (498, 500)), ('Par', (501, 504)), ('##vo', (504, 506)), ('##vir', (506, 509)), ('##us', (509, 511)), ('B1', (512, 514)), ('##9', (514, 515)), ('.', (515, 516))]\n",
      "\n",
      "\n",
      "[('La', (517, 519)), ('ex', (520, 522)), ('##plo', (522, 525)), ('##ración', (525, 531)), ('de', (532, 534)), ('la', (535, 537)), ('recién', (538, 544)), ('nacida', (545, 551)), ('tras', (552, 556)), ('la', (557, 559)), ('ces', (560, 563)), ('##ár', (563, 565)), ('##ea', (565, 567)), (',', (567, 568)), ('rev', (569, 572)), ('##el', (572, 574)), ('##ó', (574, 575)), ('un', (576, 578)), ('buen', (579, 583)), ('estado', (584, 590)), ('general', (591, 598)), (',', (598, 599)), ('con', (600, 603)), ('un', (604, 606)), ('test', (607, 611)), ('de', (612, 614)), ('A', (615, 616)), ('##p', (616, 617)), ('##gar', (617, 620)), ('de', (621, 623)), ('8', (624, 625)), ('y', (626, 627)), ('9', (628, 629)), ('puntos', (630, 636)), ('en', (637, 639)), ('el', (640, 642)), ('1º', (643, 645)), ('y', (646, 647)), ('5º', (648, 650)), ('minuto', (651, 657)), (',', (657, 658)), ('respectivamente', (659, 674)), (',', (674, 675)), ('pequeños', (676, 684)), ('hem', (685, 688)), ('##ato', (688, 691)), ('##mas', (691, 694)), ('en', (695, 697)), ('hom', (698, 701)), ('##bro', (701, 704)), ('y', (705, 706)), ('g', (707, 708)), ('##lú', (708, 710)), ('##te', (710, 712)), ('##o', (712, 713)), ('izquierdo', (714, 723)), ('##s', (723, 724)), (',', (724, 725)), ('mac', (726, 729)), ('##roc', (729, 732)), ('##efa', (732, 735)), ('##lia', (735, 738)), ('con', (739, 742)), ('font', (743, 747)), ('##ane', (747, 750)), ('##la', (750, 752)), ('anterior', (753, 761)), ('a', (762, 763)), ('tensión', (764, 771)), ('y', (772, 773)), ('pro', (774, 777)), ('##minen', (777, 782)), ('##cia', (782, 785)), ('de', (786, 788)), ('las', (789, 792)), ('ven', (793, 796)), ('##as', (796, 798)), ('ce', (799, 801)), ('##f', (801, 802)), ('##áli', (802, 805)), ('##cas', (805, 808)), ('.', (808, 809))]\n",
      "\n",
      "\n",
      "[('En', (810, 812)), ('el', (813, 815)), ('hem', (816, 819)), ('##og', (819, 821)), ('##rama', (821, 825)), ('se', (826, 828)), ('consta', (829, 835)), ('##tó', (835, 837)), ('una', (838, 841)), ('tomb', (842, 846)), ('##oci', (846, 849)), ('##top', (849, 852)), ('##enia', (852, 856)), ('grave', (857, 862)), ('(', (863, 864)), ('9', (864, 865)), ('x', (866, 867)), ('109', (868, 871)), ('/', (871, 872)), ('L', (872, 873)), (')', (873, 874)), ('.', (874, 875))]\n",
      "\n",
      "\n",
      "[('Ante', (876, 880)), ('la', (881, 883)), ('sos', (884, 887)), ('##pec', (887, 890)), ('##ha', (890, 892)), ('clínica', (893, 900)), ('de', (901, 903)), ('T', (904, 905)), ('##F', (905, 906)), ('##NA', (906, 908)), ('se', (909, 911)), ('trans', (912, 917)), ('##fund', (917, 921)), ('##ió', (921, 923)), ('una', (924, 927)), ('al', (928, 930)), ('##í', (930, 931)), ('##cu', (931, 933)), ('##ota', (933, 936)), ('de', (937, 939)), ('con', (940, 943)), ('##centra', (943, 949)), ('##do', (949, 951)), ('de', (952, 954)), ('plaque', (955, 961)), ('##tas', (961, 964)), ('de', (965, 967)), ('af', (968, 970)), ('##ére', (970, 973)), ('##sis', (973, 976)), ('ir', (977, 979)), ('##radi', (979, 983)), ('##ado', (983, 986)), (',', (986, 987)), ('de', (988, 990)), ('fe', (991, 993)), ('##not', (993, 996)), ('##ipo', (996, 999)), ('HP', (1000, 1002)), ('##A', (1002, 1003)), ('-', (1003, 1004)), ('1a', (1004, 1006)), ('des', (1007, 1010)), ('##cono', (1010, 1014)), ('##cido', (1014, 1018)), ('y', (1019, 1020)), ('se', (1021, 1023)), ('inició', (1024, 1030)), ('tratamiento', (1031, 1042)), ('con', (1043, 1046)), ('in', (1047, 1049)), ('##mun', (1049, 1052)), ('##og', (1052, 1054)), ('##lob', (1054, 1057)), ('##ulin', (1057, 1061)), ('##as', (1061, 1063)), ('end', (1064, 1067)), ('##oven', (1067, 1071)), ('##osas', (1071, 1075)), ('(', (1076, 1077)), ('I', (1077, 1078)), ('##GI', (1078, 1080)), ('##V', (1080, 1081)), (')', (1081, 1082)), ('a', (1083, 1084)), ('dos', (1085, 1088)), ('##is', (1088, 1090)), ('de', (1091, 1093)), ('1', (1094, 1095)), ('g', (1096, 1097)), ('/', (1097, 1098)), ('K', (1098, 1099)), ('##g', (1099, 1100)), ('x', (1101, 1102)), ('2', (1103, 1104)), ('días', (1105, 1109)), (',', (1109, 1110)), ('con', (1111, 1114)), ('muy', (1115, 1118)), ('buena', (1119, 1124)), ('respuesta', (1125, 1134)), ('(', (1135, 1136)), ('plaque', (1136, 1142)), ('##tas', (1142, 1145)), ('>', (1146, 1147)), ('100', (1148, 1151)), ('x', (1152, 1153)), ('109', (1154, 1157)), ('/', (1157, 1158)), ('L', (1158, 1159)), (',', (1159, 1160)), ('que', (1161, 1164)), ('se', (1165, 1167)), ('man', (1168, 1171)), ('##tuvieron', (1171, 1179)), ('a', (1180, 1181)), ('lo', (1182, 1184)), ('largo', (1185, 1190)), ('de', (1191, 1193)), ('todo', (1194, 1198)), ('el', (1199, 1201)), ('ingreso', (1202, 1209)), (')', (1209, 1210)), ('.', (1210, 1211))]\n",
      "\n",
      "\n",
      "[('Se', (1212, 1214)), ('soli', (1215, 1219)), ('##cit', (1219, 1222)), ('##ó', (1222, 1223)), ('estudio', (1224, 1231)), ('in', (1232, 1234)), ('##mun', (1234, 1237)), ('##oh', (1237, 1239)), ('##ema', (1239, 1242)), ('##tol', (1242, 1245)), ('##ógico', (1245, 1250)), ('al', (1251, 1253)), ('Centro', (1254, 1260)), ('de', (1261, 1263)), ('Trans', (1264, 1269)), ('##fusión', (1269, 1275)), ('Sang', (1276, 1280)), ('##u', (1280, 1281)), ('##íne', (1281, 1284)), ('##a', (1284, 1285)), ('de', (1286, 1288)), ('Navarra', (1289, 1296)), (',', (1296, 1297)), ('así', (1298, 1301)), ('como', (1302, 1306)), ('búsqueda', (1307, 1315)), ('de', (1316, 1318)), ('plaque', (1319, 1325)), ('##tas', (1325, 1328)), ('de', (1329, 1331)), ('dona', (1332, 1336)), ('##nte', (1336, 1339)), ('HP', (1340, 1342)), ('##A', (1342, 1343)), ('-', (1343, 1344)), ('1a', (1344, 1346)), ('negativo', (1347, 1355)), ('.', (1355, 1356))]\n",
      "\n",
      "\n",
      "[('En', (1357, 1359)), ('la', (1360, 1362)), ('e', (1363, 1364)), ('##co', (1364, 1366)), ('##grafía', (1366, 1372)), ('cerebral', (1373, 1381)), ('se', (1382, 1384)), ('apre', (1385, 1389)), ('##ció', (1389, 1392)), ('una', (1393, 1396)), ('hi', (1397, 1399)), ('##dro', (1399, 1402)), ('##ce', (1402, 1404)), ('##fal', (1404, 1407)), ('##ia', (1407, 1409)), ('grave', (1410, 1415)), ('secundaria', (1416, 1426)), ('a', (1427, 1428)), ('hem', (1429, 1432)), ('##or', (1432, 1434)), ('##rag', (1434, 1437)), ('##ia', (1437, 1439)), ('intra', (1440, 1445)), ('##vent', (1445, 1449)), ('##ricu', (1449, 1453)), ('##lar', (1453, 1456)), (',', (1456, 1457)), ('que', (1458, 1461)), ('pre', (1462, 1465)), ('##cis', (1465, 1468)), ('##ó', (1468, 1469)), ('de', (1470, 1472)), ('la', (1473, 1475)), ('col', (1476, 1479)), ('##oca', (1479, 1482)), ('##ción', (1482, 1486)), ('de', (1487, 1489)), ('un', (1490, 1492)), ('cat', (1493, 1496)), ('##éter', (1496, 1500)), ('de', (1501, 1503)), ('deriva', (1504, 1510)), ('##ción', (1510, 1514)), ('ex', (1515, 1517)), ('##tern', (1517, 1521)), ('##o', (1521, 1522)), (',', (1522, 1523)), ('a', (1524, 1525)), ('través', (1526, 1532)), ('del', (1533, 1536)), ('cual', (1537, 1541)), ('se', (1542, 1544)), ('re', (1545, 1547)), ('##co', (1547, 1549)), ('##gió', (1549, 1552)), ('líquido', (1553, 1560)), ('ce', (1561, 1563)), ('##fal', (1563, 1566)), ('##or', (1566, 1568)), ('##raq', (1568, 1571)), ('##u', (1571, 1572)), ('##íd', (1572, 1574)), ('##eo', (1574, 1576)), ('hem', (1577, 1580)), ('##or', (1580, 1582)), ('##rá', (1582, 1584)), ('##gico', (1584, 1588)), ('a', (1589, 1590)), ('presión', (1591, 1598)), ('.', (1598, 1599))]\n",
      "\n",
      "\n",
      "[('Present', (1600, 1607)), ('##ó', (1607, 1608)), ('una', (1609, 1612)), ('evolución', (1613, 1622)), ('posterior', (1623, 1632)), ('tó', (1633, 1635)), ('##rp', (1635, 1637)), ('##ida', (1637, 1640)), (',', (1640, 1641)), ('con', (1642, 1645)), ('vent', (1646, 1650)), ('##ricu', (1650, 1654)), ('##liti', (1654, 1658)), ('##s', (1658, 1659)), ('y', (1660, 1661)), ('crisis', (1662, 1668)), ('con', (1669, 1672)), ('##vul', (1672, 1675)), ('##siva', (1675, 1679)), ('##s', (1679, 1680)), (',', (1680, 1681)), ('que', (1682, 1685)), ('pre', (1686, 1689)), ('##cis', (1689, 1692)), ('##ó', (1692, 1693)), ('de', (1694, 1696)), ('tratamiento', (1697, 1708)), ('con', (1709, 1712)), ('anti', (1713, 1717)), ('##bio', (1717, 1720)), ('##tera', (1720, 1724)), ('##pia', (1724, 1727)), ('y', (1728, 1729)), ('fe', (1730, 1732)), ('##no', (1732, 1734)), ('##bar', (1734, 1737)), ('##bita', (1737, 1741)), ('##l', (1741, 1742)), (',', (1742, 1743)), ('respectivamente', (1744, 1759)), (',', (1759, 1760)), ('e', (1761, 1762)), ('im', (1763, 1765)), ('##plant', (1765, 1770)), ('##ación', (1770, 1775)), ('de', (1776, 1778)), ('una', (1779, 1782)), ('v', (1783, 1784)), ('##ál', (1784, 1786)), ('##vul', (1786, 1789)), ('##a', (1789, 1790)), ('de', (1791, 1793)), ('deriva', (1794, 1800)), ('##ción', (1800, 1804)), ('vent', (1805, 1809)), ('##rí', (1809, 1811)), ('##culo', (1811, 1815)), ('##peri', (1815, 1819)), ('##tone', (1819, 1823)), ('##al', (1823, 1825)), ('.', (1825, 1826))]\n",
      "\n",
      "\n",
      "[('Durante', (1827, 1834)), ('su', (1835, 1837)), ('ingreso', (1838, 1845)), ('se', (1846, 1848)), ('trans', (1849, 1854)), ('##fund', (1854, 1858)), ('##ió', (1858, 1860)), ('una', (1861, 1864)), ('al', (1865, 1867)), ('##í', (1867, 1868)), ('##cu', (1868, 1870)), ('##ota', (1870, 1873)), ('de', (1874, 1876)), ('con', (1877, 1880)), ('##centra', (1880, 1886)), ('##do', (1886, 1888)), ('de', (1889, 1891)), ('hem', (1892, 1895)), ('##at', (1895, 1897)), ('##íes', (1897, 1900)), ('le', (1901, 1903)), ('##uco', (1903, 1906)), ('##de', (1906, 1908)), ('##ple', (1908, 1911)), ('##ccion', (1911, 1916)), ('##ado', (1916, 1919)), ('e', (1920, 1921)), ('ir', (1922, 1924)), ('##radi', (1924, 1928)), ('##ado', (1928, 1931)), ('.', (1931, 1932))]\n",
      "\n",
      "\n",
      "[('El', (1933, 1935)), ('estudio', (1936, 1943)), ('in', (1944, 1946)), ('##mun', (1946, 1949)), ('##oh', (1949, 1951)), ('##ema', (1951, 1954)), ('##tol', (1954, 1957)), ('##ógico', (1957, 1962)), ('realizado', (1963, 1972)), ('en', (1973, 1975)), ('el', (1976, 1978)), ('Centro', (1979, 1985)), ('de', (1986, 1988)), ('Trans', (1989, 1994)), ('##fusión', (1994, 2000)), ('Sang', (2001, 2005)), ('##u', (2005, 2006)), ('##íne', (2006, 2009)), ('##a', (2009, 2010)), ('de', (2011, 2013)), ('Navarra', (2014, 2021)), ('confirmó', (2022, 2030)), ('el', (2031, 2033)), ('fe', (2034, 2036)), ('##not', (2036, 2039)), ('##ipo', (2039, 2042)), ('HP', (2043, 2045)), ('##A', (2045, 2046)), ('-', (2046, 2047)), ('1a', (2047, 2049)), ('negativo', (2050, 2058)), ('mater', (2059, 2064)), ('##no', (2064, 2066)), ('y', (2067, 2068)), ('positivo', (2069, 2077)), ('en', (2078, 2080)), ('el', (2081, 2083)), ('neo', (2084, 2087)), ('##nato', (2087, 2091)), (',', (2091, 2092)), ('así', (2093, 2096)), ('como', (2097, 2101)), ('la', (2102, 2104)), ('presencia', (2105, 2114)), ('de', (2115, 2117)), ('antic', (2118, 2123)), ('##uer', (2123, 2126)), ('##pos', (2126, 2129)), ('con', (2130, 2133)), ('es', (2134, 2136)), ('##pec', (2136, 2139)), ('##if', (2139, 2141)), ('##ici', (2141, 2144)), ('##dad', (2144, 2147)), ('anti', (2148, 2152)), ('-', (2152, 2153)), ('HP', (2153, 2155)), ('##A', (2155, 2156)), ('-', (2156, 2157)), ('1a', (2157, 2159)), ('en', (2160, 2162)), ('el', (2163, 2165)), ('sue', (2166, 2169)), ('##ro', (2169, 2171)), ('mater', (2172, 2177)), ('##no', (2177, 2179)), ('como', (2180, 2184)), ('en', (2185, 2187)), ('la', (2188, 2190)), ('recién', (2191, 2197)), ('nacida', (2198, 2204)), ('.', (2204, 2205))]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(check_id_frag, check_id_frag + train_frag[check_id]):\n",
    "    print(list(zip([tokenizer._token_dict_inv[ind] for ind in train_ind[i]][1:len(train_start_end_frag[i])+1], \n",
    "               train_start_end_frag[i])))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] G ##estan ##te de 27 años , del grupo sang ##u ##íne ##o A positivo , con ante ##cedent ##es personales de mening ##itis a los 3 años , leg ##rado por em ##bara ##zo mol ##ar ( G1 ##P ##0 ##A ##1 ) en su primera ge ##sta ##ción en 2005 y fu ##mad ##ora de 10 - 20 ci ##garri ##llos / día . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] No ante ##cedent ##es trans ##fus ##ional ##es pre ##vios . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] En la e ##co ##grafía realizada en la semana 35 de ge ##sta ##ción se det ##ect ##ó una hi ##dro ##ce ##fal ##ia fet ##al bila ##teral y oli ##goa ##mn ##ios , por lo que se program ##ó una ces ##ár ##ea para la semana 36 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] En el estudio anal ##ítico pre ##vio destaca ##ba una ser ##ología positiva ( I ##g ##M ) para el Par ##vo ##vir ##us B1 ##9 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] La ex ##plo ##ración de la recién nacida tras la ces ##ár ##ea , rev ##el ##ó un buen estado general , con un test de A ##p ##gar de 8 y 9 puntos en el 1º y 5º minuto , respectivamente , pequeños hem ##ato ##mas en hom ##bro y g ##lú ##te ##o izquierdo ##s , mac ##roc ##efa ##lia con font ##ane ##la anterior a tensión y pro ##minen ##cia de las ven ##as ce ##f ##áli ##cas . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] En el hem ##og ##rama se consta ##tó una tomb ##oci ##top ##enia grave ( 9 x 109 / L ) . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] Ante la sos ##pec ##ha clínica de T ##F ##NA se trans ##fund ##ió una al ##í ##cu ##ota de con ##centra ##do de plaque ##tas de af ##ére ##sis ir ##radi ##ado , de fe ##not ##ipo HP ##A - 1a des ##cono ##cido y se inició tratamiento con in ##mun ##og ##lob ##ulin ##as end ##oven ##osas ( I ##GI ##V ) a dos ##is de 1 g / K ##g x 2 días , con muy buena respuesta ( plaque ##tas > 100 x 109 / L , que se man ##tuvieron a lo largo de todo el ingreso ) . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] Se soli ##cit ##ó estudio in ##mun ##oh ##ema ##tol ##ógico al Centro de Trans ##fusión Sang ##u ##íne ##a de Navarra , así como búsqueda de plaque ##tas de dona ##nte HP ##A - 1a negativo . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] En la e ##co ##grafía cerebral se apre ##ció una hi ##dro ##ce ##fal ##ia grave secundaria a hem ##or ##rag ##ia intra ##vent ##ricu ##lar , que pre ##cis ##ó de la col ##oca ##ción de un cat ##éter de deriva ##ción ex ##tern ##o , a través del cual se re ##co ##gió líquido ce ##fal ##or ##raq ##u ##íd ##eo hem ##or ##rá ##gico a presión . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] Present ##ó una evolución posterior tó ##rp ##ida , con vent ##ricu ##liti ##s y crisis con ##vul ##siva ##s , que pre ##cis ##ó de tratamiento con anti ##bio ##tera ##pia y fe ##no ##bar ##bita ##l , respectivamente , e im ##plant ##ación de una v ##ál ##vul ##a de deriva ##ción vent ##rí ##culo ##peri ##tone ##al . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] Durante su ingreso se trans ##fund ##ió una al ##í ##cu ##ota de con ##centra ##do de hem ##at ##íes le ##uco ##de ##ple ##ccion ##ado e ir ##radi ##ado . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] El estudio in ##mun ##oh ##ema ##tol ##ógico realizado en el Centro de Trans ##fusión Sang ##u ##íne ##a de Navarra confirmó el fe ##not ##ipo HP ##A - 1a negativo mater ##no y positivo en el neo ##nato , así como la presencia de antic ##uer ##pos con es ##pec ##if ##ici ##dad anti - HP ##A - 1a en el sue ##ro mater ##no como en la recién nacida . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_id_frag = sum(train_frag[:check_id])\n",
    "for frag in train_ind[check_id_frag:check_id_frag + train_frag[check_id]]:\n",
    "    print(' '.join([tokenizer._token_dict_inv[ind] for ind in frag]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7025.000000\n",
       "mean        0.304911\n",
       "std         0.652322\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         6.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fragment labels distribution\n",
    "pd.Series(np.sum(train_y, axis=1)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development corpus\n",
    "\n",
    "Only development texts that are annotated with CIE-Procedimiento codes are considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some dev documents (texts) are not annotated \n",
    "len(set(df_text_dev[\"doc_id\"]) - set(df_codes_dev_ner[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_doc_list = sorted(set(df_codes_dev_ner[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.1 ms, sys: 51 µs, total: 42.1 ms\n",
      "Wall time: 41.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ss_sub_corpus_path = ss_corpus_path + \"dev/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_dev = load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [00:03<00:00, 61.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.68 s, sys: 15.6 ms, total: 3.7 s\n",
      "Wall time: 3.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dev_ind, dev_seg, dev_y, dev_frag, dev_start_end_frag = ss_create_frag_input_data_bert(df_text=df_text_dev, \n",
    "                                                  text_col=text_col, \n",
    "                                                  df_ann=df_codes_dev_ner, doc_list=dev_doc_list, ss_dict=ss_dict_dev,\n",
    "                                                  tokenizer=tokenizer, lab_encoder=mlb_encoder, seq_len=SEQ_LEN,\n",
    "                                                  greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3808, 128)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3808, 128)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3808, 727)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3808"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_start_end_frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    222.000000\n",
       "mean      17.153153\n",
       "std        8.327785\n",
       "min        4.000000\n",
       "25%       11.000000\n",
       "50%       15.000000\n",
       "75%       21.000000\n",
       "max       65.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check n_frag distribution across texts\n",
    "pd.Series(dev_frag).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a randomly selected text and its encoded version\n",
    "check_id = np.random.randint(low=0, high=len(dev_doc_list), size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S1130-01082008000900016-1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_doc_list[check_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Se presenta el caso de un varón de 68 años asintomático, sin antecedentes de interés, remitido para estudio de una lesión a nivel del proceso uncinado del páncreas. La misma fue detectada incidentalmente por ecografía abdominal realizada para el estudio una de lumbalgia.\\n\\nEn la imagen de la tomografía computerizada de abdomen se describe una masa inhomogénea a nivel del proceso uncinado con un diámetro en sentido anteroposterior de 3,6 cm, borrosidad de la grasa peripancreática y dilatación del conducto pancreático principal.\\n\\nSe procede a una exploración con equipo lineal de ecoendoscopia (PENTAX UX 3630) donde se excluye la invasión de vía biliar y estructuras adyacentes. El estudio citológico del material obtenido por PAAF guiada por ecoendoscopia fue negativo para malignidad.\\nCon la sospecha de adenocarcinoma se realiza una duodenopancreatectomía cefálica con disección de ganglios linfáticos. Macroscópicamente se describe una lesión grisácea bien delimitada de 1,8 cm x 1 cm de consistencia blanda con aspecto necrótico en su centro con diagnóstico histopatológico de quiste linfoepitelial.\\n\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_dev[df_text_dev[\"doc_id\"] == dev_doc_list[check_id]][text_col].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[()] \n",
      "\n",
      "[('bw40zzz',)] \n",
      "\n",
      "[('bw20',)] \n",
      "\n",
      "[('0fjb8zz',)] \n",
      "\n",
      "[()] \n",
      "\n",
      "[('0db9', '0fbg')] \n",
      "\n",
      "[()] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_id_frag = sum(dev_frag[:check_id])\n",
    "for i in range(check_id_frag, check_id_frag + dev_frag[check_id]):\n",
    "    print(mlb_encoder.inverse_transform(np.array([dev_y[i]])), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Se', (0, 2)), ('presenta', (3, 11)), ('el', (12, 14)), ('caso', (15, 19)), ('de', (20, 22)), ('un', (23, 25)), ('var', (26, 29)), ('##ón', (29, 31)), ('de', (32, 34)), ('68', (35, 37)), ('años', (38, 42)), ('asi', (43, 46)), ('##nto', (46, 49)), ('##mático', (49, 55)), (',', (55, 56)), ('sin', (57, 60)), ('ante', (61, 65)), ('##cedent', (65, 71)), ('##es', (71, 73)), ('de', (74, 76)), ('interés', (77, 84)), (',', (84, 85)), ('re', (86, 88)), ('##mitido', (88, 94)), ('para', (95, 99)), ('estudio', (100, 107)), ('de', (108, 110)), ('una', (111, 114)), ('lesión', (115, 121)), ('a', (122, 123)), ('nivel', (124, 129)), ('del', (130, 133)), ('proceso', (134, 141)), ('un', (142, 144)), ('##cina', (144, 148)), ('##do', (148, 150)), ('del', (151, 154)), ('p', (155, 156)), ('##án', (156, 158)), ('##cre', (158, 161)), ('##as', (161, 163)), ('.', (163, 164))]\n",
      "\n",
      "\n",
      "[('La', (165, 167)), ('misma', (168, 173)), ('fue', (174, 177)), ('det', (178, 181)), ('##ecta', (181, 185)), ('##da', (185, 187)), ('incident', (188, 196)), ('##almente', (196, 203)), ('por', (204, 207)), ('e', (208, 209)), ('##co', (209, 211)), ('##grafía', (211, 217)), ('ab', (218, 220)), ('##dom', (220, 223)), ('##inal', (223, 227)), ('realizada', (228, 237)), ('para', (238, 242)), ('el', (243, 245)), ('estudio', (246, 253)), ('una', (254, 257)), ('de', (258, 260)), ('lu', (261, 263)), ('##mba', (263, 266)), ('##lgi', (266, 269)), ('##a', (269, 270)), ('.', (270, 271))]\n",
      "\n",
      "\n",
      "[('En', (273, 275)), ('la', (276, 278)), ('imagen', (279, 285)), ('de', (286, 288)), ('la', (289, 291)), ('tom', (292, 295)), ('##ografía', (295, 302)), ('computer', (303, 311)), ('##izada', (311, 316)), ('de', (317, 319)), ('abdomen', (320, 327)), ('se', (328, 330)), ('describe', (331, 339)), ('una', (340, 343)), ('masa', (344, 348)), ('in', (349, 351)), ('##hom', (351, 354)), ('##og', (354, 356)), ('##én', (356, 358)), ('##ea', (358, 360)), ('a', (361, 362)), ('nivel', (363, 368)), ('del', (369, 372)), ('proceso', (373, 380)), ('un', (381, 383)), ('##cina', (383, 387)), ('##do', (387, 389)), ('con', (390, 393)), ('un', (394, 396)), ('diámetro', (397, 405)), ('en', (406, 408)), ('sentido', (409, 416)), ('ante', (417, 421)), ('##rop', (421, 424)), ('##oster', (424, 429)), ('##ior', (429, 432)), ('de', (433, 435)), ('3', (436, 437)), (',', (437, 438)), ('6', (438, 439)), ('cm', (440, 442)), (',', (442, 443)), ('bor', (444, 447)), ('##ros', (447, 450)), ('##idad', (450, 454)), ('de', (455, 457)), ('la', (458, 460)), ('gras', (461, 465)), ('##a', (465, 466)), ('per', (467, 470)), ('##ipa', (470, 473)), ('##nc', (473, 475)), ('##re', (475, 477)), ('##ática', (477, 482)), ('y', (483, 484)), ('dil', (485, 488)), ('##ata', (488, 491)), ('##ción', (491, 495)), ('del', (496, 499)), ('conduct', (500, 507)), ('##o', (507, 508)), ('pan', (509, 512)), ('##cre', (512, 515)), ('##ático', (515, 520)), ('principal', (521, 530)), ('.', (530, 531))]\n",
      "\n",
      "\n",
      "[('Se', (533, 535)), ('procede', (536, 543)), ('a', (544, 545)), ('una', (546, 549)), ('ex', (550, 552)), ('##plo', (552, 555)), ('##ración', (555, 561)), ('con', (562, 565)), ('equipo', (566, 572)), ('lineal', (573, 579)), ('de', (580, 582)), ('e', (583, 584)), ('##coe', (584, 587)), ('##ndos', (587, 591)), ('##co', (591, 593)), ('##pia', (593, 596)), ('(', (597, 598)), ('PE', (598, 600)), ('##NT', (600, 602)), ('##AX', (602, 604)), ('U', (605, 606)), ('##X', (606, 607)), ('363', (608, 611)), ('##0', (611, 612)), (')', (612, 613)), ('donde', (614, 619)), ('se', (620, 622)), ('ex', (623, 625)), ('##clu', (625, 628)), ('##ye', (628, 630)), ('la', (631, 633)), ('invasión', (634, 642)), ('de', (643, 645)), ('vía', (646, 649)), ('bili', (650, 654)), ('##ar', (654, 656)), ('y', (657, 658)), ('estructuras', (659, 670)), ('ad', (671, 673)), ('##ya', (673, 675)), ('##centes', (675, 681)), ('.', (681, 682))]\n",
      "\n",
      "\n",
      "[('El', (683, 685)), ('estudio', (686, 693)), ('cit', (694, 697)), ('##ológico', (697, 704)), ('del', (705, 708)), ('material', (709, 717)), ('ob', (718, 720)), ('##tenido', (720, 726)), ('por', (727, 730)), ('PA', (731, 733)), ('##AF', (733, 735)), ('gu', (736, 738)), ('##iada', (738, 742)), ('por', (743, 746)), ('e', (747, 748)), ('##coe', (748, 751)), ('##ndos', (751, 755)), ('##co', (755, 757)), ('##pia', (757, 760)), ('fue', (761, 764)), ('negativo', (765, 773)), ('para', (774, 778)), ('mali', (779, 783)), ('##gni', (783, 786)), ('##dad', (786, 789)), ('.', (789, 790))]\n",
      "\n",
      "\n",
      "[('Con', (791, 794)), ('la', (795, 797)), ('sos', (798, 801)), ('##pec', (801, 804)), ('##ha', (804, 806)), ('de', (807, 809)), ('ad', (810, 812)), ('##eno', (812, 815)), ('##car', (815, 818)), ('##cino', (818, 822)), ('##ma', (822, 824)), ('se', (825, 827)), ('realiza', (828, 835)), ('una', (836, 839)), ('duo', (840, 843)), ('##den', (843, 846)), ('##opa', (846, 849)), ('##nc', (849, 851)), ('##reate', (851, 856)), ('##cto', (856, 859)), ('##mí', (859, 861)), ('##a', (861, 862)), ('ce', (863, 865)), ('##f', (865, 866)), ('##áli', (866, 869)), ('##ca', (869, 871)), ('con', (872, 875)), ('dis', (876, 879)), ('##ec', (879, 881)), ('##ción', (881, 885)), ('de', (886, 888)), ('gang', (889, 893)), ('##lios', (893, 897)), ('li', (898, 900)), ('##n', (900, 901)), ('##f', (901, 902)), ('##áticos', (902, 908)), ('.', (908, 909))]\n",
      "\n",
      "\n",
      "[('Mac', (910, 913)), ('##ros', (913, 916)), ('##có', (916, 918)), ('##pica', (918, 922)), ('##mente', (922, 927)), ('se', (928, 930)), ('describe', (931, 939)), ('una', (940, 943)), ('lesión', (944, 950)), ('gris', (951, 955)), ('##áce', (955, 958)), ('##a', (958, 959)), ('bien', (960, 964)), ('del', (965, 968)), ('##imit', (968, 972)), ('##ada', (972, 975)), ('de', (976, 978)), ('1', (979, 980)), (',', (980, 981)), ('8', (981, 982)), ('cm', (983, 985)), ('x', (986, 987)), ('1', (988, 989)), ('cm', (990, 992)), ('de', (993, 995)), ('consiste', (996, 1004)), ('##ncia', (1004, 1008)), ('bland', (1009, 1014)), ('##a', (1014, 1015)), ('con', (1016, 1019)), ('aspecto', (1020, 1027)), ('ne', (1028, 1030)), ('##c', (1030, 1031)), ('##ró', (1031, 1033)), ('##tico', (1033, 1037)), ('en', (1038, 1040)), ('su', (1041, 1043)), ('centro', (1044, 1050)), ('con', (1051, 1054)), ('dia', (1055, 1058)), ('##gnóstico', (1058, 1066)), ('his', (1067, 1070)), ('##top', (1070, 1073)), ('##ato', (1073, 1076)), ('##lógico', (1076, 1082)), ('de', (1083, 1085)), ('qui', (1086, 1089)), ('##ste', (1089, 1092)), ('li', (1093, 1095)), ('##nfo', (1095, 1098)), ('##ep', (1098, 1100)), ('##itel', (1100, 1104)), ('##ial', (1104, 1107)), ('.', (1107, 1108))]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(check_id_frag, check_id_frag + dev_frag[check_id]):\n",
    "    print(list(zip([tokenizer._token_dict_inv[ind] for ind in dev_ind[i]][1:len(dev_start_end_frag[i])+1], \n",
    "               dev_start_end_frag[i])))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Se presenta el caso de un var ##ón de 68 años asi ##nto ##mático , sin ante ##cedent ##es de interés , re ##mitido para estudio de una lesión a nivel del proceso un ##cina ##do del p ##án ##cre ##as . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] La misma fue det ##ecta ##da incident ##almente por e ##co ##grafía ab ##dom ##inal realizada para el estudio una de lu ##mba ##lgi ##a . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] En la imagen de la tom ##ografía computer ##izada de abdomen se describe una masa in ##hom ##og ##én ##ea a nivel del proceso un ##cina ##do con un diámetro en sentido ante ##rop ##oster ##ior de 3 , 6 cm , bor ##ros ##idad de la gras ##a per ##ipa ##nc ##re ##ática y dil ##ata ##ción del conduct ##o pan ##cre ##ático principal . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] Se procede a una ex ##plo ##ración con equipo lineal de e ##coe ##ndos ##co ##pia ( PE ##NT ##AX U ##X 363 ##0 ) donde se ex ##clu ##ye la invasión de vía bili ##ar y estructuras ad ##ya ##centes . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] El estudio cit ##ológico del material ob ##tenido por PA ##AF gu ##iada por e ##coe ##ndos ##co ##pia fue negativo para mali ##gni ##dad . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] Con la sos ##pec ##ha de ad ##eno ##car ##cino ##ma se realiza una duo ##den ##opa ##nc ##reate ##cto ##mí ##a ce ##f ##áli ##ca con dis ##ec ##ción de gang ##lios li ##n ##f ##áticos . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "[CLS] Mac ##ros ##có ##pica ##mente se describe una lesión gris ##áce ##a bien del ##imit ##ada de 1 , 8 cm x 1 cm de consiste ##ncia bland ##a con aspecto ne ##c ##ró ##tico en su centro con dia ##gnóstico his ##top ##ato ##lógico de qui ##ste li ##nfo ##ep ##itel ##ial . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_id_frag = sum(dev_frag[:check_id])\n",
    "for frag in dev_ind[check_id_frag:check_id_frag + dev_frag[check_id]]:\n",
    "    print(' '.join([tokenizer._token_dict_inv[ind] for ind in frag]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3808.000000\n",
       "mean        0.309086\n",
       "std         0.637504\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         5.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fragment labels distribution\n",
    "pd.Series(np.sum(dev_y, axis=1)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Development corpus\n",
    "\n",
    "We merge the previously generated datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices\n",
    "train_dev_ind = np.concatenate((train_ind, dev_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10833, 128)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segments\n",
    "train_dev_seg = np.concatenate((train_seg, dev_seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10833, 128)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y\n",
    "train_dev_y = np.concatenate((train_y, dev_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10833, 727)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "Using the corpus of labeled sentences, we fine-tune the model on a multi-label sentence classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "# Prevent GPU memory allocation problems\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "\n",
    "model = load_trained_model_from_checkpoint(\n",
    "    config_file=config_path, \n",
    "    checkpoint_file=checkpoint_path, \n",
    "    training=training,                                       \n",
    "    trainable=trainable, \n",
    "    seq_len=SEQ_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Input-Token:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'Input-Segment:0' shape=(?, 128) dtype=float32>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Encoder-12-FeedForward-Norm/add_1:0' shape=(?, 128, 768) dtype=float32>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras_bert.layers import Extract\n",
    "\n",
    "dense_cls = Extract(index=0, name='Extract')(model.output) # In order to extract CLS token embedding\n",
    "dense_out = Dense(units=num_labels, kernel_initializer=glorot_uniform(seed=random_seed))(dense_cls) # Multi-label classification\n",
    "outputs = Activation('sigmoid')(dense_out)\n",
    "\n",
    "model = Model(model.inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Input-Token:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'Input-Segment:0' shape=(?, 128) dtype=float32>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'activation_1/Sigmoid:0' shape=(?, 727) dtype=float32>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "10833/10833 [==============================] - 162s 15ms/step - loss: 0.2437\n",
      "Epoch 2/34\n",
      "10833/10833 [==============================] - 160s 15ms/step - loss: 0.0253\n",
      "Epoch 3/34\n",
      " 3632/10833 [=========>....................] - ETA: 1:46 - loss: 0.0106"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras_radam import RAdam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RAdam(learning_rate=LR),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[train_dev_ind, train_dev_seg],\n",
    "    y=train_dev_y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set predictions\n",
    "\n",
    "Finally, the predictions made by the model on the test set are saved. For this purpose, firstly, each sentence from the test corpus must be converted into a sequence of subwords (input IDs and attention mask arrays). Then, the predictions made by the model at the sentence-level are saved, to be further evaluated at document-level (see `results/CodiEsp-P/Evaluation.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.06 ms, sys: 95 µs, total: 6.16 ms\n",
      "Wall time: 5.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_path = corpus_path + \"test/text_files/\"\n",
    "test_files = [f for f in os.listdir(test_path) if os.path.isfile(test_path + f)]\n",
    "test_data = load_text_files(test_files, test_path)\n",
    "df_text_test = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in test_files], 'raw_text': test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1698-44472004000400012-1</td>\n",
       "      <td>Varón de 54 años de edad, remitido a nuestro s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude a nuestras consultas a un paciente que p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0212-16112009000300015-1</td>\n",
       "      <td>Se trató de un varón de 77 años con antecedent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1139-76322014000500014-1</td>\n",
       "      <td>Niño de cinco años derivado por su pediatra de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0212-71992004000300009-1</td>\n",
       "      <td>Varón de 22 años de edad que acude a consultas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1698-44472004000400012-1   \n",
       "1  S1130-05582012000300005-1   \n",
       "2  S0212-16112009000300015-1   \n",
       "3  S1139-76322014000500014-1   \n",
       "4  S0212-71992004000300009-1   \n",
       "\n",
       "                                            raw_text  \n",
       "0  Varón de 54 años de edad, remitido a nuestro s...  \n",
       "1  Acude a nuestras consultas a un paciente que p...  \n",
       "2  Se trató de un varón de 77 años con antecedent...  \n",
       "3  Niño de cinco años derivado por su pediatra de...  \n",
       "4  Varón de 22 años de edad que acude a consultas...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Varón de 54 años de edad, remitido a nuestro servicio en mayo del 2003 por presentar odontalgia en relación con un tercer molar inferior derecho erupcionado. A la inspección oral se pudo observar la existencia de una tumefacción que expandía las corticales vestibulo-linguales, en la región del tercer molar mandibular derecho, cariado por distal. La mucosa oral estaba indemne, y no se palpaban adenomegalias cervicales. El paciente refería la existencia de una hipoestesia en el territorio de distribución del nervio mentoniano de quince días de evolución. En la ortopantomografía, se evidenció la presencia de una imagen radiolúcida, de contornos poco definidos, en el cuerpo mandibular derecho. Dos días después, bajo anestesia local, se procedió a la exodoncia del tercer molar y curetaje-biopsia del tejido subyacente. Durante el acto operatorio, se produjo una intensa hemorragia, que pudo ser cohibida con el empleo de Surgicel (Johnson & Johnson, Nuevo Brunswick, NJ) y mediante el empaquetado en el lecho alveolar de cera de hueso.\\n\\nEl hemograma y el estudio de coagulación postoperato-rios no mostraron alteraciones significativas. El diagnóstico histopatológico del material remitido fue de: metástasis mandibular por hepatocarcinoma bien diferenciado. Las células neoplásicas no se teñían con las citoqueratinas 19 y 20, ni con la alfa-fetoproteina, pero si mostraron una intensa tinción granular citoplasmática con el marcador hepatocito N.\\n\\nEntre los antecedentes personales del paciente, destacaban una historia de diabetes tipo II de 8 años de evolución, controlada con hipoglucemiantes orales. Se trataba de un bebedor de 130 g. etanol/día desde los 30 años, y fumador de 2 paquetes de cigarrillos/día desde los 20 años. Un año antes de nuestra valoración, el enfermo había sido diagnosticado de cirrosis hepática (estadio A de Child Pugh: 5/15), y de hepatocarcinoma multicéntrico con afectación de los segmentos II, III, y IV, siendo intervenido mediante resección hepática parcial, al mes de su diagnostico. Previamente se había realizado un estudio completo que incluyó gammagrafía ósea con tecnecio 99-MDP y tomografía computarizada de cráneo, pulmón, abdomen y pelvis, sin objetivar la presencia de metástasis. Los valores séricos de alfa-fetoproteina eran, en los controles postoperatorios, normales (3,6 ng/ml).\\nA los 15 días de nuestra intervención se objetivó una marcada elevación de los niveles de alfa-fetoproteina (221 ng/ml), evidenciándose mediante gammagrafía ósea y resonancia magnética la existencia de múltiples metástasis que afectaban al occipital izquierdo, cuerpo esternal, pelvis, y múltiples vértebras. El paciente fue sometido a radioterapia paliativa sobre las lesiones vertebrales (10 Gy a la semana de Co 60) sin mejoría, siendo éxitus a los seis meses de nuestra biopsia.\\n\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_test.raw_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_list = sorted(set(df_text_test[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 44 µs, total: 9.05 ms\n",
      "Wall time: 8.38 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ss_sub_corpus_path = ss_corpus_path + \"test/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_test = load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 168.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 12.4 ms, total: 1.57 s\n",
      "Wall time: 1.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_ind, test_seg, _, test_frag, _ = ss_create_frag_input_data_bert(df_text=df_text_test, \n",
    "                                                  text_col=text_col,\n",
    "                                                  # Since labels are ignored, we pass df_codes_train_ner as df_ann\n",
    "                                                  df_ann=df_codes_train_ner, doc_list=test_doc_list, ss_dict=ss_dict_test,\n",
    "                                                  tokenizer=tokenizer, lab_encoder=mlb_encoder, seq_len=SEQ_LEN,\n",
    "                                                  greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.82 s, sys: 603 ms, total: 6.42 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_preds = model.predict([test_ind, test_seg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3955, 727)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_path = \"../results/CodiEsp-P/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.21 ms, sys: 4.65 ms, total: 6.87 ms\n",
      "Wall time: 6.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save(file=results_dir_path + \"predictions/mbert_galen_seed_\" + str(random_seed) + \"_test_preds.npy\", arr=test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
